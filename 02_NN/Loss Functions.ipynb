{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_Loss Functions.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"BCAU9rxdGcF1","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSngpeHcGcF4","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RhTv1AQlGcFv","colab_type":"code","colab":{}},"source":["%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o5VNjgeNGcF6","colab_type":"text"},"source":["### Regression loss  \n","* MSE\n","* MAE\n","* Huber loss\n","* Los cosh loss\n","* Quantile loss"]},{"cell_type":"markdown","metadata":{"id":"ybz969anGcF7","colab_type":"text"},"source":["#### Mean Square Error (MSE/ L2 Loss)\n","$ MSE = \\sum\\limits_{i=1}^n  {(y_i - y_i^p)}^2 $  "]},{"cell_type":"code","metadata":{"id":"AVCOaCm2GcF8","colab_type":"code","colab":{}},"source":["def mse(true, pred):\n","    \"\"\"\n","    true: array of true values    \n","    pred: array of predicted values\n","    \n","    returns: mean square error loss\n","    \"\"\"\n","    \n","    return np.mean((true - pred)**2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eVXtcY1sGcF-","colab_type":"code","colab":{}},"source":["fig, ax1 = plt.subplots(1,1, figsize = (7,5))\n","\n","# array of same target value 10000 times\n","target = 100\n","pred = np.arange(-10000,10000, 2)\n","\n","loss_mse = [mse(target, pred[i]) for i in range(len(pred))]\n","\n","# plot \n","ax1.plot(pred, loss_mse)\n","ax1.set_xlabel('Predictions')\n","ax1.set_ylabel('Loss')\n","ax1.set_title(\"MSE Loss vs. Predictions\")\n","\n","fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PEpZ0I1PGcGD","colab_type":"text"},"source":["#### Mean Absolute Error (MAE/ L1 loss)\n","$ MAE = \\sum\\limits_{i=1}^n  {|y_i - y_i^p|} $  "]},{"cell_type":"code","metadata":{"id":"YxTk7MuIGcGD","colab_type":"code","colab":{}},"source":["def mae(true, pred):\n","    \"\"\"\n","    true: array of true values    \n","    pred: array of predicted values\n","    \n","    returns: mean absolute error loss\n","    \"\"\"\n","    \n","    return np.sum(np.mean(np.abs(true - pred)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-vAg9b0DGcGG","colab_type":"code","colab":{}},"source":["fig, ax1 = plt.subplots(1,1, figsize = (7,5))\n","\n","# array of same target value 10000 times\n","target = 100\n","pred = np.arange(-10000,10000, 2)\n","\n","loss_mae = [mae(target, pred[i]) for i in range(len(pred))]\n","\n","# plot \n","ax1.plot(pred, loss_mae)\n","ax1.set_xlabel('Predictions')\n","ax1.set_ylabel('Loss')\n","ax1.set_title(\"MAE Loss vs. Predictions\")\n","\n","fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Q7xSC--GcGJ","colab_type":"text"},"source":["#### Smooth Mean Absolute Error/ Huber Loss "]},{"cell_type":"code","metadata":{"id":"wbP05uxhGcGK","colab_type":"code","colab":{}},"source":["def sm_mae(true, pred, delta):\n","    \"\"\"\n","    true: array of true values    \n","    pred: array of predicted values\n","    \n","    returns: smoothed mean absolute error loss\n","    \"\"\"\n","    loss = np.where(np.abs(true-pred) < delta , 0.5*((true-pred)**2), delta*np.abs(true - pred) - 0.5*(delta**2))\n","    return np.sum(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"91Fvd8QtGcGM","colab_type":"code","colab":{}},"source":["fig, ax1 = plt.subplots(1,1, figsize = (7,5))\n","\n","target = 0\n","pred = np.arange(-10,10, 0.02)\n","\n","delta = [0.1, 1, 10]\n","\n","losses_huber = [[sm_mae(target, pred[i], q) for i in range(len(pred))] for q in delta]\n","\n","# plot \n","for i in range(len(delta)):\n","    ax1.plot(pred, losses_huber[i], label = delta[i])\n","ax1.set_xlabel('Predictions')\n","ax1.set_ylabel('Loss')\n","ax1.set_title(\"Huber Loss/ Smooth MAE Loss vs. Predicted values (Color: Deltas)\")\n","ax1.legend()\n","ax1.set_ylim(bottom=-1, top = 15)\n","\n","fig.tight_layout()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0IKXMHm-GcGP","colab_type":"text"},"source":["#### Log cosh loss\n","$ L(y, y^p) = \\sum\\limits_{i=1}^n  {\\log(\\cosh(y_i^p-y_i))} $  "]},{"cell_type":"code","metadata":{"id":"TAjQ0lhVGcGQ","colab_type":"code","colab":{}},"source":["def logcosh(true, pred):\n","    loss = np.log(np.cosh(pred - true))\n","    return np.sum(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hri3K1XJGcGS","colab_type":"code","colab":{}},"source":["fig, ax1 = plt.subplots(1,1, figsize = (7,5))\n","\n","target = 0\n","pred = np.arange(-10,10, 0.02)\n","\n","loss_logcosh = [logcosh(target, pred[i]) for i in range(len(pred))]\n","\n","# plot \n","ax1.plot(pred, loss_logcosh)\n","ax1.set_xlabel('Predictions')\n","ax1.set_ylabel('Loss')\n","ax1.set_title(\"Log-Cosh Loss vs. Predictions\")\n","\n","fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xdJQF_x9GcGW","colab_type":"text"},"source":["#### Quantile loss\n","\n"," $ L_\\gamma(y, y^p) = \\sum\\limits_{i=y_i<y_i^p}  ({\\gamma-1}).|y_i - y_i^p| + \\sum\\limits_{i=y_i\\geq y_i^p}  ({\\gamma}).|y_i - y_i^p|  $  "]},{"cell_type":"code","metadata":{"id":"oPEZMuf6GcGW","colab_type":"code","colab":{}},"source":["def quan(true, pred, theta):\n","    loss = np.where(true >= pred, theta*(np.abs(true-pred)), (1-theta)*(np.abs(true-pred)))\n","    return np.sum(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZP1Hg8_GcGY","colab_type":"code","colab":{}},"source":["fig, ax1 = plt.subplots(1,1, figsize = (7,5))\n","\n","target = 0\n","pred = np.arange(-10,10, 0.02)\n","\n","quantiles = [0.25, 0.5, 0.75]\n","\n","losses_quan = [[quan(target, pred[i], q) for i in range(len(pred))] for q in quantiles]\n","\n","# plot \n","for i in range(len(quantiles)):\n","    ax1.plot(pred, losses_quan[i], label = quantiles[i])\n","ax1.set_xlabel('Predictions')\n","ax1.set_ylabel('Quantile Loss')\n","ax1.set_title(\"Loss with Predicted values (Color: Quantiles)\")\n","ax1.legend()\n","\n","fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mh-1AePeGcGc","colab_type":"text"},"source":["#### **All regression losses in single plot**"]},{"cell_type":"code","metadata":{"id":"USM9XJNjGcGd","colab_type":"code","colab":{}},"source":["fig, ax1 = plt.subplots(1,1, figsize = (10,6.5))\n","\n","target = np.repeat(0, 1000)\n","pred = np.arange(-10,10, 0.02)\n","\n","# calculating loss function for all predictions. \n","loss_mse = [mse(target[i], pred[i]) for i in range(len(pred))]\n","loss_mae = [mae(target[i], pred[i]) for i in range(len(pred))]\n","loss_sm_mae1 = [sm_mae(target[i], pred[i], 5) for i in range(len(pred))]\n","loss_sm_mae2 = [sm_mae(target[i], pred[i], 10) for i in range(len(pred))]\n","loss_logcosh = [logcosh(target[i], pred[i]) for i in range(len(pred))]\n","loss_quan1 = [quan(target[i], pred[i], 0.25) for i in range(len(pred))]\n","\n","\n","losses = [loss_mse, loss_mae, loss_sm_mae1, loss_sm_mae2, loss_logcosh, loss_quan1]\n","names = ['MSE', 'MAE','Huber (5)', 'Huber (10)', 'Log-cosh', 'Quantile (0.25)']\n","cmap = ['#d53e4f',\n","'#fc8d59',\n","'#fee08b',\n","'#e6f598',\n","'#99d594',\n","'#3288bd']\n","\n","for lo in range(len(losses)):\n","    ax1.plot(pred, losses[lo], label = names[lo], color= cmap[lo])\n","ax1.set_xlabel('Predictions')\n","ax1.set_ylabel('Loss')\n","ax1.set_title(\"Loss with Predicted values\")\n","ax1.legend()\n","ax1.set_ylim(bottom=0, top=40)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xM6e_DzbGcGi","colab_type":"text"},"source":["### Classifications loss\n","\n","* Binary cross entropy \n","* Focal loss\n","* Hinge loss\n","* Square loss\n"]},{"cell_type":"markdown","metadata":{"id":"tmm2Q2mpGcGj","colab_type":"text"},"source":["####Â Binary cross entropy or negative log likelihood"]},{"cell_type":"code","metadata":{"id":"ELneD-6EGcGj","colab_type":"code","colab":{}},"source":["def bin_ce(true, pred):\n","    \"\"\"\n","    true: array of true values    \n","    pred: array of predicted values\n","    \n","    returns: binary cross entropy loss\n","    \"\"\"\n","    loss = np.where(true==1, np.log(pred), np.log(1-pred))\n","    return -np.sum(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7NMYAhsfGcGl","colab_type":"code","colab":{}},"source":["fig, ax1 = plt.subplots(1,1)\n","\n","# array of same target value 10000 times\n","target = 1 # considering prediction to be 1\n","pred = np.arange(0,1, 0.0001) # all predictions between 0 and 1 for 10k values\n","\n","# calculating loss function for all predictions. \n","loss_bin_ce = [bin_ce(target, pred[i]) for i in range(len(pred))]\n","\n","# plot for binary cross entropy\n","ax1.plot(pred, loss_bin_ce)\n","ax1.set_xlabel('Predictions')\n","ax1.set_ylabel('Binary Cross Entropy Loss/ Log Loss')\n","ax1.set_title(\"Loss with Predicted values\")\n","\n","fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YzeMrEqQGcGr","colab_type":"text"},"source":["#### Focal loss"]},{"cell_type":"code","metadata":{"id":"7xQ0D3pCGcGt","colab_type":"code","colab":{}},"source":["def focal(true, pred, gamma):\n","    \"\"\"\n","    true: array of true values    \n","    pred: array of predicted values\n","    \n","    returns: binary cross entropy loss\n","    \"\"\"\n","    loss = np.where(true==1, (1-pred)**gamma*(np.log(pred)), pred**gamma*(np.log(1-pred)))\n","    return -np.sum(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"EgsU0NyEGcGu","colab_type":"code","colab":{}},"source":["fig, ax1 = plt.subplots(1,1)\n","\n","# array of same target value 10000 times\n","target = np.repeat(1, 10000) # considering prediction to be 1\n","pred = np.arange(0,1, 0.0001) # all predictions b/w 0 and 1 for 10k values\n","\n","# calculating loss function for all predictions. \n","gammas = [0, 0.5, 1, 2, 5]\n","losses_focal = [[focal(target[i], pred[i], gamma) for i in range(len(pred))] for gamma in gammas]\n","\n","# plot for binary cross entropy\n","for i in range(len(gammas)):\n","    ax1.plot(pred, losses_focal[i], label = gammas[i])\n","ax1.set_xlabel('Predictions')\n","ax1.set_ylabel('Focal Loss')\n","ax1.set_title(\"Loss with Predicted values (Color: Gammas)\")\n","ax1.legend()\n","\n","# make right and top lines invisible\n","ax1.spines['top'].set_visible(False)    # Make the top axis line for a plot invisible\n","ax1.spines['right'].set_visible(False) # Make the right axis line for a plot invisible\n","\n","fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4qdc3JRaGcGx","colab_type":"text"},"source":["#### Hinge loss"]},{"cell_type":"code","metadata":{"id":"z83-z4GHGcGy","colab_type":"code","colab":{}},"source":["def hinge(true, pred):\n","    \"\"\"\n","    true: array of true values    \n","    pred: array of predicted values\n","    \n","    returns: negative log likelihood loss\n","    \"\"\"\n","    loss = np.max((0, (1 - pred*true)))\n","    return np.sum(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"6GqX1ieGGcG0","colab_type":"code","colab":{}},"source":["fig, ax1 = plt.subplots(1,1)\n","\n","# array of same target value 10000 times\n","target = np.repeat(1, 10000) # considering prediction to be 1\n","pred = np.arange(0,1, 0.0001) # all predictions b/w 0 and 1 for 10k values\n","\n","# calculating loss function for all predictions. \n","loss_hinge = [hinge(target[i], pred[i]) for i in range(len(pred))]\n","\n","# plot for hinge\n","ax1.plot(pred, loss_hinge)\n","ax1.set_xlabel('Predictions')\n","ax1.set_ylabel('Hinge Loss')\n","ax1.set_title(\"Loss with Predicted values\")\n","\n","fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sbOKCldeGcG3","colab_type":"text"},"source":["#### Square loss"]},{"cell_type":"code","metadata":{"id":"e-ILsVEuGcG3","colab_type":"code","colab":{}},"source":["def sq_loss(true, pred):\n","    \"\"\"\n","    true: array of true values    \n","    pred: array of predicted values\n","    \n","    returns: negative log likelihood loss\n","    \"\"\"\n","    loss = (1 - pred*true)**2\n","    return np.sum(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"8SDBfpwdGcG5","colab_type":"code","colab":{}},"source":["fig, ax1 = plt.subplots(1,1)\n","\n","# array of same target value 10000 times\n","target = np.repeat(1, 10000) # considering prediction to be 1\n","pred = np.arange(0,1, 0.0001) # all predictions b/w 0 and 1 for 10k values\n","\n","# calculating loss function for all predictions. \n","loss_sq = [sq_loss(target[i], pred[i]) for i in range(len(pred))]\n","\n","# plot for hinge\n","ax1.plot(pred, loss_sq)\n","ax1.set_xlabel('Predictions')\n","ax1.set_ylabel('Square Loss')\n","ax1.set_title(\"Loss with Predicted values\")\n","\n","fig.tight_layout()"],"execution_count":null,"outputs":[]}]}